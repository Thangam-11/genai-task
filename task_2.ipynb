{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement 2: Text Generation\n",
    "\n",
    "* Problem: Create a basic text generation model using a pre-trained transformer (e.g., GPT-3).\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* Use the Hugging Face Transformers library.\n",
    "\n",
    "* Generate coherent text based on a given prompt. Evaluation Criteria:\n",
    "\n",
    "* Ability to load and use pre-trained models.\n",
    "\n",
    "* Quality and coherence of the generated text.\n",
    "\n",
    "* Understanding and application of the transformer model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step by  solution \n",
    "\n",
    "1. Set Up the Environment\n",
    "\n",
    "2. Load a Pre-trained Model using open ai  transformer models like gpt_4  using api-token  \n",
    "\n",
    "3. Use the load model to python dotenv method and create  text based given prompts \n",
    "\n",
    "4. Evalaute the results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Unlikely Friendship\n",
      "\n",
      "Once upon a time, in an old, creaky house in the heart of the city, lived a feisty orange cat named Whiskers and a shrewd, little rat named Squeaky. Whiskers was the house owner's pet, and Squeaky was an uninvited guest who lived in the basement, unnoticed by the humans.\n",
      "\n",
      "In the beginning, their relationship was just like any other cat and rat story. Whiskers, with his hunter instincts, would always try to catch Squeaky, and Squeaky, with his nimble body and quick thinking, would always manage to escape.\n",
      "\n",
      "Their days were filled with endless chases and hide-and-seek games.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "#  Prompt Template\n",
    "template = \"\"\"\n",
    "You are a creative writing assistant. Write a short story based on the following prompt:\n",
    "\n",
    "{prompt}\n",
    "\n",
    "Ensure the story has a beginning, middle, and end, and is engaging to read.\n",
    "\"\"\"\n",
    "\n",
    "#  Create a Prompt Template object\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"prompt\"],  \n",
    "    template=template\n",
    ")\n",
    "\n",
    "# Initialize the ChatOpenAI model\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7, max_tokens=150)\n",
    "\n",
    "#  Create an LLMChain  prompt template and the LLM\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# Generate text by running the chain\n",
    "\n",
    "user_prompt = \"Give me cat and rat story .\"\n",
    "\n",
    "# Run the LLMChain with the user prompt\n",
    "generated_story = llm_chain.run(user_prompt)\n",
    "\n",
    "print(generated_story)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation \n",
    "\n",
    "1. Loads environment variables from a .env file using the python-dotenv library.\n",
    "this retrieves the OpenAI API key from the environment variable OPENAI_API_KEY.\n",
    "\n",
    "2.  created Prompt template using langchain  that template variable  contains string format .Transfomer model write a story based on given prompts.\n",
    "\n",
    "3. Initializing ChatOpenAI GPT-4 model.\n",
    "\n",
    "4. create llm chains \n",
    "\n",
    "5. Genreate the text based on user prompts .\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
